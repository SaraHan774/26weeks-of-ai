---
layout: default
title: Learning Resources
---

# í•™ìŠµ ë¦¬ì†ŒìŠ¤

26ì£¼ LLM í•™ìŠµ ì—¬ì •ì— í•„ìš”í•œ ëª¨ë“  ìë£Œë¥¼ í•œ ê³³ì— ëª¨ì•˜ìŠµë‹ˆë‹¤.

---

## ğŸ“š í•„ìˆ˜ ë„ì„œ

### ë”¥ëŸ¬ë‹ ê¸°ì´ˆ

| ë„ì„œëª… | ì €ì | ì„¤ëª… | ë§í¬ |
|:------|:-----|:-----|:-----|
| ë°‘ë°”ë‹¥ë¶€í„° ì‹œì‘í•˜ëŠ” ë”¥ëŸ¬ë‹ | ì‚¬ì´í†  ê³ í‚¤ | ì‹ ê²½ë§ ê¸°ì´ˆë¶€í„° CNNê¹Œì§€ (4-9ì£¼) | [í•œë¹›ë¯¸ë””ì–´](https://www.hanbit.co.kr/store/books/look.php?p_code=B8475831198) |
| ë°‘ë°”ë‹¥ë¶€í„° ì‹œì‘í•˜ëŠ” ë”¥ëŸ¬ë‹ 2 | ì‚¬ì´í†  ê³ í‚¤ | ìì—°ì–´ ì²˜ë¦¬ì™€ RNN (10-14ì£¼) | [í•œë¹›ë¯¸ë””ì–´](https://www.hanbit.co.kr/store/books/look.php?p_code=B8950212853) |
| ì í”„ íˆ¬ íŒŒì´ì¬ | ë°•ì‘ìš© | Python ê¸°ì´ˆ (1ì£¼) | [ì˜¨ë¼ì¸ ë¬´ë£Œ](https://wikidocs.net/book/1) |

---

## ğŸ¬ ì˜ìƒ ê°•ì˜

### ìˆ˜í•™ & ë”¥ëŸ¬ë‹ ê¸°ì´ˆ

| ê°•ì˜ëª… | ì±„ë„ | ì£¼ì°¨ | ì„¤ëª… |
|:------|:-----|:----:|:-----|
| [Essence of Linear Algebra](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab) | 3Blue1Brown | 3ì£¼ | ì„ í˜•ëŒ€ìˆ˜ ì§ê´€ì  ì´í•´ (í•œê¸€ ìë§‰) |
| [Essence of Calculus](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr) | 3Blue1Brown | 3ì£¼ | ë¯¸ì ë¶„ í•µì‹¬ ê°œë… |
| [Neural Networks](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) | 3Blue1Brown | 4ì£¼ | ì‹ ê²½ë§ ì‹œê°í™” ì„¤ëª… |
| [But what is a convolution?](https://www.youtube.com/watch?v=KuXjwB4LzSA) | 3Blue1Brown | 8ì£¼ | CNNì˜ ì»¨ë³¼ë£¨ì…˜ ì´í•´ |

### Python & í”„ë¡œê·¸ë˜ë°

| ê°•ì˜ëª… | ì±„ë„ | ì£¼ì°¨ | ì„¤ëª… |
|:------|:-----|:----:|:-----|
| [Python Tutorial for Beginners](https://www.youtube.com/watch?v=rfscVS0vtbw) | Corey Schafer | 1ì£¼ | Python ê¸°ì´ˆ ë¬¸ë²• |
| [NumPy Tutorial](https://www.youtube.com/watch?v=QUT1VHiLmmI) | freeCodeCamp | 2ì£¼ | NumPy ê¸°ì´ˆ (1ì‹œê°„) |
| [PyTorch for Deep Learning](https://www.youtube.com/watch?v=V_xro1bcAuA) | freeCodeCamp | 5ì£¼ | PyTorch ì…ë¬¸ |

### ë”¥ëŸ¬ë‹ ì‹¤ì „

| ê°•ì˜ëª… | í”Œë«í¼ | ì£¼ì°¨ | ì„¤ëª… |
|:------|:------|:----:|:-----|
| [Practical Deep Learning for Coders](https://course.fast.ai/) | fast.ai | 6-8ì£¼ | ì‹¤ì „ ì¤‘ì‹¬ ë”¥ëŸ¬ë‹ |
| [Backpropagation explained](https://www.youtube.com/watch?v=Ilg3gGewQ5U) | Andrej Karpathy | 7ì£¼ | ì—­ì „íŒŒ ìƒì„¸ ì„¤ëª… |

### Transformer & LLM

| ê°•ì˜ëª… | ì±„ë„ | ì£¼ì°¨ | ì„¤ëª… |
|:------|:-----|:----:|:-----|
| [Let's build GPT](https://www.youtube.com/watch?v=kCc8FmEb1nY) | Andrej Karpathy | 16-18ì£¼ | GPTë¥¼ ë°‘ë°”ë‹¥ë¶€í„° êµ¬í˜„ |
| [State of GPT](https://www.youtube.com/watch?v=bZQun8Y4L2A) | Andrej Karpathy | 22ì£¼ | í˜„ëŒ€ LLM ê°œìš” |
| [Transformer Neural Networks](https://www.youtube.com/watch?v=TQQlZhbC5ps) | Computerphile | 15ì£¼ | Transformer ì„¤ëª… |

### NLP ê°•ì˜

| ê°•ì˜ëª… | í”Œë«í¼ | ì£¼ì°¨ | ì„¤ëª… |
|:------|:------|:----:|:-----|
| [Hugging Face NLP Course](https://huggingface.co/learn/nlp-course/chapter1/1) | Hugging Face | 10-11ì£¼ | í† í°í™”ì™€ ì„ë² ë”© |
| [StatQuest: RNN, LSTM, GRU](https://www.youtube.com/watch?v=AsNTP8Kwu80) | StatQuest | 12ì£¼ | ìˆœí™˜ ì‹ ê²½ë§ ì„¤ëª… |

---

## ğŸ“ MIT OpenCourseWare (MIT OCW)

### ìˆ˜í•™ ê¸°ì´ˆ

| ê°•ì˜ëª… | ê°•ì˜ ë²ˆí˜¸ | ê°•ì‚¬ | ì„¤ëª… |
|:------|:---------|:-----|:-----|
| [Linear Algebra](https://ocw.mit.edu/courses/18-06-linear-algebra-spring-2010/) | 18.06 | Gilbert Strang | â­ ì „ì„¤ì ì¸ ì„ í˜•ëŒ€ìˆ˜ ê°•ì˜ (1,000ë§Œ+ ì¡°íšŒìˆ˜) |
| [Linear Algebra (Scholar)](https://ocw.mit.edu/courses/18-06sc-linear-algebra-fall-2011/) | 18.06SC | - | ììŠµìš© ë²„ì „ (ë¬¸ì œí’€ì´ ì˜ìƒ í¬í•¨) |
| [Matrix Methods in Data Analysis, Signal Processing, and Machine Learning](https://ocw.mit.edu/courses/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/) | 18.065 | Gilbert Strang | ë¨¸ì‹ ëŸ¬ë‹ì„ ìœ„í•œ í–‰ë ¬ ì´ë¡  (2018) |

### ë”¥ëŸ¬ë‹ & ë¨¸ì‹ ëŸ¬ë‹

| ê°•ì˜ëª… | ê°•ì˜ ë²ˆí˜¸ | í•™ê¸° | ì„¤ëª… |
|:------|:---------|:-----|:-----|
| [Introduction to Deep Learning](https://ocw.mit.edu/courses/6-s191-introduction-to-deep-learning-january-iap-2020/) | 6.S191 | IAP 2020 | ë”¥ëŸ¬ë‹ ì…ë¬¸ (LLM, Generative AI í¬í•¨) |
| [Introduction to Deep Learning (ê³µì‹ ì‚¬ì´íŠ¸)](https://introtodeeplearning.com/) | 6.S191 | 2026 | ìµœì‹  ë²„ì „ (ë§¤ë…„ 1ì›” ì—…ë°ì´íŠ¸) |
| [Hands-on Deep Learning](https://ocw.mit.edu/courses/15-773-hands-on-deep-learning-spring-2024/) | 15.773 | Spring 2024 | ì‹¤ìŠµ ì¤‘ì‹¬ ë”¥ëŸ¬ë‹ (ë¹„ì •í˜• ë°ì´í„° ì²˜ë¦¬) |
| [Deep Learning](https://phillipi.github.io/6.7960/) | 6.7960 | Fall 2024 | CNN, RNN, Transformer, Graph Nets ì‹¬í™” |

### ìì—°ì–´ ì²˜ë¦¬ (NLP)

| ê°•ì˜ëª… | ê°•ì˜ ë²ˆí˜¸ | í•™ê¸° | ì„¤ëª… |
|:------|:---------|:-----|:-----|
| [Quantitative Methods for NLP (Advanced NLP)](https://mit-6861.github.io/) | 6.861/6.8610 | ìµœì‹  | â­ Transformer, MoE, Quantization, Mamba í¬í•¨ |
| [Advanced Natural Language Processing](https://ocw.mit.edu/courses/6-864-advanced-natural-language-processing-fall-2005/) | 6.864 | Fall 2005 | NLP ê¸°ì´ˆ (êµ¬ë²„ì „ì´ì§€ë§Œ ê°œë…ì€ ìœ íš¨) |
| [Natural Language Processing](https://courses.csail.mit.edu/6.864/) | 6.806/6.864 | ìµœì‹  | ë”¥ëŸ¬ë‹ ê¸°ë°˜ NLP (ì „í†µì  ì ‘ê·¼ê³¼ ë¹„êµ) |

### í•™ìŠµ íŒ

- **18.06 Linear Algebra**: ë”¥ëŸ¬ë‹ ìˆ˜í•™ ê¸°ì´ˆë¥¼ ë‹¤ì§€ê¸°ì— ìµœê³ . 3ì£¼ì°¨ ìˆ˜í•™ í•™ìŠµê³¼ ë³‘í–‰ ì¶”ì²œ
- **6.S191 Introduction to Deep Learning**: ìµœì‹  LLM íŠ¸ë Œë“œë¥¼ ë¹ ë¥´ê²Œ íŒŒì•…í•˜ê¸° ì¢‹ìŒ. 5-9ì£¼ì°¨ì™€ í•¨ê»˜ í•™ìŠµ
- **6.861 Quantitative Methods for NLP**: Transformer ì´í›„ì˜ ìµœì‹  ê¸°ë²•ê¹Œì§€ ë‹¤ë£¸. 15ì£¼ì°¨ ì´í›„ ì°¸ê³ 

---

## ğŸ“ ë¸”ë¡œê·¸ & ì•„í‹°í´

### í•„ë… ë¸”ë¡œê·¸ (Jay Alammar)

| ì œëª© | ì£¼ì°¨ | ì„¤ëª… | ë§í¬ |
|:-----|:----:|:-----|:-----|
| The Illustrated Transformer | 15ì£¼ | â­ ìµœê³ ì˜ Transformer ì‹œê°í™” | [Link](https://jalammar.github.io/illustrated-transformer/) |
| The Illustrated BERT | 19ì£¼ | BERT êµ¬ì¡° ìƒì„¸ ì„¤ëª… | [Link](https://jalammar.github.io/illustrated-bert/) |
| Visualizing Neural Machine Translation | 14ì£¼ | Attention ë©”ì»¤ë‹ˆì¦˜ ì‹œê°í™” | [Link](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/) |
| The Illustrated GPT-2 | 19ì£¼ | GPT-2 ì‘ë™ ì›ë¦¬ | [Link](https://jalammar.github.io/illustrated-gpt2/) |

### Hugging Face ë¸”ë¡œê·¸

| ì œëª© | ì£¼ì°¨ | ì„¤ëª… | ë§í¬ |
|:-----|:----:|:-----|:-----|
| RLHF ì„¤ëª… | 23ì£¼ | ì¸ê°„ í”¼ë“œë°± ê°•í™”í•™ìŠµ | [Link](https://huggingface.co/blog/rlhf) |
| Illustrated Word2Vec | 11ì£¼ | Word2Vec ì‹œê°ì  ì„¤ëª… | [Link](https://jalammar.github.io/illustrated-word2vec/) |

### Anthropic ë¸”ë¡œê·¸

| ì œëª© | ì£¼ì°¨ | ì„¤ëª… | ë§í¬ |
|:-----|:----:|:-----|:-----|
| Constitutional AI | 25ì£¼ | Anthropicì˜ AI ì •ë ¬ ë°©ë²• | [Link](https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback) |
| Claude's Character | - | Claude ê°œë°œ ê³¼ì • | [Link](https://www.anthropic.com/research/claude-character) |

---

## ğŸ’» ì½”ë“œ ì €ì¥ì†Œ & íŠœí† ë¦¬ì–¼

### ì‹¤ìŠµ ì½”ë“œ

| ì €ì¥ì†Œëª… | ì£¼ì°¨ | ìš©ë„ | ë§í¬ |
|:--------|:----:|:-----|:-----|
| nanoGPT | 17-18, 20ì£¼ | GPTë¥¼ ë°‘ë°”ë‹¥ë¶€í„° êµ¬í˜„ | [GitHub](https://github.com/karpathy/nanoGPT) |
| Annotated Transformer | 16ì£¼ | Transformer ì½”ë“œ ë¼ì¸ë³„ ì„¤ëª… | [Link](https://nlp.seas.harvard.edu/2018/04/03/attention.html) |
| PyTorch 60 Minute Blitz | 5ì£¼ | PyTorch ê³µì‹ íŠœí† ë¦¬ì–¼ | [Link](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) |

### ë¼ì´ë¸ŒëŸ¬ë¦¬

| ë¼ì´ë¸ŒëŸ¬ë¦¬ | ì£¼ì°¨ | ìš©ë„ | ë§í¬ |
|:----------|:----:|:-----|:-----|
| Hugging Face Transformers | 19, 25ì£¼ | ì‚¬ì „í•™ìŠµ ëª¨ë¸ ì‚¬ìš© | [GitHub](https://github.com/huggingface/transformers) |
| trl (Transformer Reinforcement Learning) | 23ì£¼ | RLHF ì‹¤ìŠµ | [GitHub](https://github.com/huggingface/trl) |
| LangChain | 25ì£¼ | RAG ì‹œìŠ¤í…œ êµ¬ì¶• | [Docs](https://docs.langchain.com/) |
| Gensim | 11ì£¼ | Word2Vec í•™ìŠµ | [Docs](https://radimrehurek.com/gensim/) |

---

## ğŸ“„ í•µì‹¬ ë…¼ë¬¸

### Transformer & Attention

| ë…¼ë¬¸ ì œëª© | ì—°ë„ | ì£¼ì°¨ | ì„¤ëª… | ë§í¬ |
|:---------|:----:|:----:|:-----|:-----|
| Attention is All You Need | 2017 | 15ì£¼ | Transformer ì›ë³¸ ë…¼ë¬¸ | [arXiv](https://arxiv.org/abs/1706.03762) |
| BERT: Pre-training of Deep Bidirectional Transformers | 2018 | 19ì£¼ | BERT ë…¼ë¬¸ | [arXiv](https://arxiv.org/abs/1810.04805) |

### Word Embeddings

| ë…¼ë¬¸ ì œëª© | ì—°ë„ | ì£¼ì°¨ | ì„¤ëª… | ë§í¬ |
|:---------|:----:|:----:|:-----|:-----|
| Efficient Estimation of Word Representations in Vector Space | 2013 | 11ì£¼ | Word2Vec ë…¼ë¬¸ | [arXiv](https://arxiv.org/abs/1301.3781) |

### Sequence Models

| ë…¼ë¬¸ ì œëª© | ì—°ë„ | ì£¼ì°¨ | ì„¤ëª… | ë§í¬ |
|:---------|:----:|:----:|:-----|:-----|
| Sequence to Sequence Learning with Neural Networks | 2014 | 13ì£¼ | Seq2Seq ê¸°ì´ˆ | [arXiv](https://arxiv.org/abs/1409.3215) |
| Neural Machine Translation by Jointly Learning to Align and Translate | 2014 | 14ì£¼ | Attention ë©”ì»¤ë‹ˆì¦˜ | [arXiv](https://arxiv.org/abs/1409.0473) |

### Modern LLMs

| ë…¼ë¬¸ ì œëª© | ì—°ë„ | ì£¼ì°¨ | ì„¤ëª… | ë§í¬ |
|:---------|:----:|:----:|:-----|:-----|
| Language Models are Few-Shot Learners | 2020 | 22ì£¼ | GPT-3 ë…¼ë¬¸ | [arXiv](https://arxiv.org/abs/2005.14165) |
| Training language models to follow instructions with human feedback | 2022 | 23ì£¼ | InstructGPT (RLHF) | [arXiv](https://arxiv.org/abs/2203.02155) |
| Chain-of-Thought Prompting Elicits Reasoning | 2022 | 24ì£¼ | Chain-of-Thought | [arXiv](https://arxiv.org/abs/2201.11903) |
| Large Language Models are Zero-Shot Reasoners | 2022 | 24ì£¼ | Zero-shot ì¶”ë¡  | [arXiv](https://arxiv.org/abs/2205.11916) |

### Scaling Laws

| ë…¼ë¬¸ ì œëª© | ì—°ë„ | ì£¼ì°¨ | ì„¤ëª… | ë§í¬ |
|:---------|:----:|:----:|:-----|:-----|
| Scaling Laws for Neural Language Models | 2020 | 21ì£¼ | OpenAI Scaling Laws | [arXiv](https://arxiv.org/abs/2001.08361) |
| Training Compute-Optimal Large Language Models | 2022 | 21ì£¼ | Chinchilla ë…¼ë¬¸ | [arXiv](https://arxiv.org/abs/2203.15556) |

---

## ğŸŒ ì˜¨ë¼ì¸ í”Œë«í¼

### í•™ìŠµ í”Œë«í¼

- **[PyTorch ê³µì‹ íŠœí† ë¦¬ì–¼](https://pytorch.org/tutorials/)** - PyTorch í•™ìŠµ
- **[Hugging Face Course](https://huggingface.co/learn)** - NLP & Transformers
- **[fast.ai](https://www.fast.ai/)** - ì‹¤ì „ ë”¥ëŸ¬ë‹
- **[Papers with Code](https://paperswithcode.com/)** - ë…¼ë¬¸ + ì½”ë“œ êµ¬í˜„

### ì»¤ë®¤ë‹ˆí‹°

- **[r/MachineLearning](https://www.reddit.com/r/MachineLearning/)** - Reddit ML ì»¤ë®¤ë‹ˆí‹°
- **[Hugging Face Forums](https://discuss.huggingface.co/)** - NLP ì§ˆë¬¸/ë‹µë³€
- **[PyTorch Forums](https://discuss.pytorch.org/)** - PyTorch ì§ˆë¬¸/ë‹µë³€
- **[AI Korea](https://www.facebook.com/groups/AIKoreaOpen/)** - í•œêµ­ AI ì»¤ë®¤ë‹ˆí‹°

### ë„êµ¬

- **[Google Colab](https://colab.research.google.com/)** - ë¬´ë£Œ GPU í™˜ê²½
- **[Kaggle Notebooks](https://www.kaggle.com/code)** - ë°ì´í„°ì…‹ + ë…¸íŠ¸ë¶
- **[Weights & Biases](https://wandb.ai/)** - ì‹¤í—˜ íŠ¸ë˜í‚¹

---

## ğŸ“– ì¶”ê°€ ì½ì„ê±°ë¦¬

### ì…ë¬¸ìë¥¼ ìœ„í•œ ê°€ì´ë“œ

- **[Dive into Deep Learning](https://d2l.ai/)** - ë¬´ë£Œ ì˜¨ë¼ì¸ êµê³¼ì„œ
- **[Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/)** - Michael Nielsen
- **[Understanding Deep Learning](https://udlbook.github.io/udlbook/)** - Simon Prince (2023)

### í•œêµ­ì–´ ìë£Œ

- **[í…ì„œí”Œë¡œ ë¸”ë¡œê·¸](https://blog.tensorflow.org/?hl=ko)** - TensorFlow ê³µì‹ ë¸”ë¡œê·¸
- **[PyTorch í•œêµ­ì–´ íŠœí† ë¦¬ì–¼](https://tutorials.pytorch.kr/)** - PyTorch í•œê¸€ ë²ˆì—­
- **[ëª¨ë‘ì˜ ì—°êµ¬ì†Œ](https://modulabs.co.kr/)** - AI í•™ìŠµ ì»¤ë®¤ë‹ˆí‹°

---

<div style="text-align: center; margin-top: 60px; padding: 30px; background-color: #f6f8fa; border-radius: 8px;">
  <p style="font-size: 14px; color: #586069; margin: 0;">
    ğŸ’¡ ì´ ë¦¬ì†ŒìŠ¤ë“¤ì€ <a href="/roadmap">26ì£¼ ë¡œë“œë§µ</a>ì„ ë”°ë¼ê°€ë©° ë‹¨ê³„ì ìœ¼ë¡œ í™œìš©í•˜ì„¸ìš”.
  </p>
</div>
