---
title: "Attention is All You Need ë…¼ë¬¸ ì½ê¸°"
date: 2026-01-16
---

## ì—­ì‚¬ë¥¼ ë°”ê¾¼ ë…¼ë¬¸

ì´ë²ˆ ì£¼ëŠ” 2017ë…„ Googleì´ ë°œí‘œí•œ "Attention is All You Need" ë…¼ë¬¸ì„ ì½ê³  ì´í•´í•˜ëŠ” ì£¼ì…ë‹ˆë‹¤.

### ì™œ ì¤‘ìš”í•œê°€?

ì´ ë…¼ë¬¸ì€ í˜„ëŒ€ LLMì˜ ê¸°ì´ˆê°€ ë˜ëŠ” **Transformer** ì•„í‚¤í…ì²˜ë¥¼ ì†Œê°œí–ˆìŠµë‹ˆë‹¤.
- GPT, BERT, Claude, ChatGPT ëª¨ë‘ Transformer ê¸°ë°˜
- RNN/LSTMì„ ëŒ€ì²´í•˜ëŠ” ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„

### í•µì‹¬ ê°œë…

#### 1. Self-Attention

ë¬¸ì¥ ë‚´ ë‹¨ì–´ë“¤ì´ ì„œë¡œ ì–´ë–»ê²Œ ê´€ë ¨ë˜ì–´ ìˆëŠ”ì§€ ê³„ì‚°í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜

```python
# Self-Attentionì˜ í•µì‹¬ ì•„ì´ë””ì–´ (ì˜ì‚¬ ì½”ë“œ)
def self_attention(query, key, value):
    # 1. Queryì™€ Keyì˜ ìœ ì‚¬ë„ ê³„ì‚°
    scores = matmul(query, key.T) / sqrt(d_k)

    # 2. Softmaxë¡œ í™•ë¥  ë¶„í¬ ë³€í™˜
    weights = softmax(scores)

    # 3. Valueì— ê°€ì¤‘ì¹˜ ì ìš©
    output = matmul(weights, value)

    return output
```

#### 2. Multi-Head Attention

ì—¬ëŸ¬ ê°œì˜ Attentionì„ ë³‘ë ¬ë¡œ ìˆ˜í–‰í•˜ì—¬ ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ì •ë³´ í¬ì°©

#### 3. Positional Encoding

ë‹¨ì–´ì˜ ìˆœì„œ ì •ë³´ë¥¼ ì„ë² ë”©ì— ì¶”ê°€
- RNNê³¼ ë‹¬ë¦¬ TransformerëŠ” ìˆœì„œ ì •ë³´ê°€ ì—†ìŒ
- Sin/Cos í•¨ìˆ˜ë¡œ ìœ„ì¹˜ ì •ë³´ ì¸ì½”ë”©

### Jay Alammarì˜ "Illustrated Transformer"

ë…¼ë¬¸ê³¼ í•¨ê»˜ [Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) ë¸”ë¡œê·¸ë¥¼ ì½ì—ˆìŠµë‹ˆë‹¤.
ì‹œê°í™”ê°€ ì •ë§ í›Œë¥­í•´ì„œ ê°œë… ì´í•´ì— í° ë„ì›€ì´ ë˜ì—ˆìŠµë‹ˆë‹¤!

### ì´í•´í•œ ê²ƒ

- âœ… Attentionì´ "ì–´ë””ì— ì§‘ì¤‘í• ì§€" ê²°ì •í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜ì„ì„ ì´í•´
- âœ… Query, Key, Valueì˜ ì—­í•  íŒŒì•…
- âœ… ì™œ RNNë³´ë‹¤ ë³‘ë ¬í™”ì— ìœ ë¦¬í•œì§€ ì´í•´

### ì•„ì§ ì–´ë ¤ìš´ ê²ƒ

- â“ Positional Encodingì˜ ìˆ˜ì‹ì´ ì™œ Sin/Così¸ì§€
- â“ Multi-Headê°€ ì •í™•íˆ ì–´ë–»ê²Œ ë‹¤ë¥¸ ê´€ì ì„ ì œê³µí•˜ëŠ”ì§€
- â“ Layer Normalization vs Batch Normalization

### ì£¼ë§ ì‹¤ìŠµ ê³„íš

ë…¼ë¬¸ì˜ Figure 1(Transformer ì•„í‚¤í…ì²˜)ì„ ì§ì ‘ ê·¸ë¦¬ë©´ì„œ ê° ì»´í¬ë„ŒíŠ¸ì˜ ì—­í• ì„ ì •ë¦¬í•  ì˜ˆì •ì…ë‹ˆë‹¤.

### ì°¸ê³  ìë£Œ

- ğŸ“„ [Attention is All You Need](https://arxiv.org/abs/1706.03762) (ì›ë³¸ ë…¼ë¬¸)
- ğŸ“ [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) (Jay Alammar)
- ğŸ¬ [Transformer Neural Networks Explained](https://www.youtube.com/watch?v=TQQlZhbC5ps) (Computerphile)
